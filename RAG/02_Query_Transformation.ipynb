{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zv7AGt3o4fZB",
      "metadata": {
        "id": "zv7AGt3o4fZB"
      },
      "outputs": [],
      "source": [
        "! pip install langchain langchain-google-genai langchain_community tiktoken chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e7adc2b",
      "metadata": {
        "id": "4e7adc2b"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import os\n",
        "os.environ['LANGCHAIN_TRACING_V2']='true'\n",
        "os.environ['LANGCHAIN_ENDPOING']='https://api.smith.langchain.com'\n",
        "os.environ['LANGCHAIN_API_KEY']='LANGCHAIN_API_KEY'\n",
        "os.environ['GOOGLE_API_KEY']='GOOGLE_API_KEY'\n",
        "llm=ChatGoogleGenerativeAI(model='gemini-1.5-flash')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b72db105",
      "metadata": {
        "id": "b72db105"
      },
      "source": [
        "# Multi Query\n",
        "Our model will crate multiple number of query from user's query. This will help to LLM to fetch relevent answer from the vectorstore.\n",
        "* Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3656cd5b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3656cd5b",
        "outputId": "5f17fee4-58ef-447c-91e9-3c663a4fd03b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "### Indexing ###\n",
        "# Load blog\n",
        "import bs4 # BeautifulSoup will help to provide you clean content from webpage\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "blog_docs=loader.load()\n",
        "\n",
        "# Split\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter=RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=300,chunk_overlap=50)\n",
        "\n",
        "# Make split\n",
        "splits=text_splitter.split_documents(blog_docs)\n",
        "\n",
        "# Index\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "vectorstore=Chroma.from_documents(documents=splits,embedding=GoogleGenerativeAIEmbeddings(model='models/embedding-001'))\n",
        "retriever=vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BgZkAHPz-IB1",
      "metadata": {
        "id": "BgZkAHPz-IB1"
      },
      "source": [
        "# Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "61fd5faa",
      "metadata": {
        "id": "61fd5faa"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "\n",
        "# Multi Query: Different Perspectives -> We are creating multiple question from user's question for better simlarity search in vectorDB.\n",
        "template = \"\"\"You are an AI language model assistant. Your task is to generate five\n",
        "different versions of the given user question to retrieve relevant documents from a vector\n",
        "database. By generating multiple perspectives on the user question, your goal is to help\n",
        "the user overcome some of the limitations of the distance-based similarity search.\n",
        "Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
        "\n",
        "prompt_perspectives=ChatPromptTemplate.from_template(template)\n",
        "\n",
        "generate_queries=(\n",
        "    prompt_perspectives\n",
        "    | ChatGoogleGenerativeAI(model='gemini-1.5-flash',temperature=0)\n",
        "    | StrOutputParser()\n",
        "    | (lambda x:x.split('\\n'))\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7Fv5exUcB-SF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Fv5exUcB-SF",
        "outputId": "ee6f9a1e-47c3-4fab-824f-cab8a3f4913f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-06be9bc56585>:10: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
            "  return[loads(doc) for doc in unique_docs]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.load import dumps,loads\n",
        "\n",
        "def get_unique_union(documents:list[list]):\n",
        "  \"\"\" Unique union of retrieved docs\"\"\"\n",
        "  # Flatten list of lists, and convert each document to string.\n",
        "  flattended_docs=[dumps(doc) for sublist in documents for doc in sublist]\n",
        "  # Get unique documents\n",
        "  unique_docs=list(set(flattended_docs))\n",
        "  # Return\n",
        "  return[loads(doc) for doc in unique_docs]\n",
        "\n",
        "# Retrieve\n",
        "question='What is task decomposistion for LLM agents ?'\n",
        "retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
        "docs=retrieval_chain.invoke({'question':question})\n",
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9uNjTJfhCHTj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uNjTJfhCHTj",
        "outputId": "8fcdb04e-5e07-438b-f463-22f5c1129242"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='}\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:'),\n",
              " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='GOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\\n2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the commands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate within a few minutes'),\n",
              " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.'),\n",
              " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Here are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\\\nThen you will pick one clarifying question, and wait for an answer from the user.\\\\n\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Summary of areas that need clarification:\\\\n1. Specifics of the Super Mario game (e.g. level design, characters, gameplay mechanics)\\\\n2. Details about the MVC components (e.g. which components are in each file)\\\\n3. Keyboard control implementation (e.g. which keys to use, how to handle input)\\\\n\\\\nClarifying question:\\\\nCan you provide more details about the Super Mario game, such as level design, characters, and gameplay mechanics?\"\\n  },'),\n",
              " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'),\n",
              " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:'),\n",
              " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Resources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.'),\n",
              " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'),\n",
              " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:'),\n",
              " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Or\\n@article{weng2023agent,\\n  title   = \"LLM-powered Autonomous Agents\",\\n  author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Jun\",\\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#\\n[1] Wei et al. “Chain of thought prompting elicits reasoning in large language models.” NeurIPS 2022\\n[2] Yao et al. “Tree of Thoughts: Dliberate Problem Solving with Large Language Models.” arXiv preprint arXiv:2305.10601 (2023).\\n[3] Liu et al. “Chain of Hindsight Aligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al. “LLM+P: Empowering Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).')]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ekCq0aBhEK4w",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "ekCq0aBhEK4w",
        "outputId": "4fee0daa-f8dc-45ef-d713-06535aae49f1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Task decomposition for LLM agents is the process of breaking down large, complex tasks into smaller, more manageable subgoals.  This allows the agent to handle complex problems more efficiently.  Methods include:\\n\\n* **Chain of Thought (CoT):**  A prompting technique instructing the model to \"think step by step,\" decomposing the task into smaller steps.\\n* **Tree of Thoughts:** An extension of CoT that explores multiple reasoning possibilities at each step, creating a tree structure of potential solutions.  Search can be breadth-first or depth-first.\\n* **LLM prompting:**  Simple prompts like \"Steps for XYZ. 1.\", or \"What are the subgoals for achieving XYZ?\" can elicit task decomposition from the LLM.\\n* **Task-specific instructions:**  Instructions tailored to the task type (e.g., \"Write a story outline\" for writing a novel).\\n* **Human input:**  Humans can directly provide the task decomposition.'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from operator import itemgetter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# RAG\n",
        "template = \"\"\"Answer the following question based on this context:\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt=ChatPromptTemplate.from_template(template)\n",
        "llm=ChatGoogleGenerativeAI(model='gemini-1.5-flash',temperature=0)\n",
        "\n",
        "final_rag_chain=(\n",
        "    {'context':retrieval_chain,\n",
        "     'question':itemgetter('question')}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "final_rag_chain.invoke({'question':question})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "B7j4GoPfGwQm",
      "metadata": {
        "id": "B7j4GoPfGwQm"
      },
      "source": [
        "# RAG Fusion-\n",
        "Sends multiple versions of your question,  receives results for each question, mixes them and ranks them to get the best answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "uuK2ZHnkGGTI",
      "metadata": {
        "id": "uuK2ZHnkGGTI"
      },
      "outputs": [],
      "source": [
        "# Prompt\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# RAG- Fusion\n",
        "template=\"\"\"You are a helpful assistant that generates multiple search queries based on a single input query. \\n\n",
        "Generate multiple search queries related to: {question} \\n\n",
        "Output (4 queries):\"\"\"\n",
        "prompt_rag_fusion=ChatPromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1oYnaEmkHiWa",
      "metadata": {
        "id": "1oYnaEmkHiWa"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Creating chains -> It is a sequence of steps that take input,transform it into output\n",
        "generate_queries=(\n",
        "    prompt_rag_fusion\n",
        "    | ChatGoogleGenerativeAI(model='gemini-1.5-flash')\n",
        "    | StrOutputParser()\n",
        "    | (lambda x:x.split('\\n'))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "SLFeCKXqIMZw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLFeCKXqIMZw",
        "outputId": "d90ff9c2-6ad6-4b0e-d1d7-cb3358478a83"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.load import dumps, loads\n",
        "\n",
        "def reciprocal_rank_fusion(results: list[list], k=60):\n",
        "    \"\"\" Reciprocal_rank_fusion that takes multiple lists of ranked documents\n",
        "        and an optional parameter k used in the RRF formula \"\"\"\n",
        "\n",
        "    # Initialize a dictionary to hold fused scores for each unique document\n",
        "    fused_scores = {}\n",
        "\n",
        "    # Iterate through each list of ranked documents\n",
        "    for docs in results:\n",
        "        # Iterate through each document in the list, with its rank (position in the list)\n",
        "        for rank, doc in enumerate(docs):\n",
        "            # Convert the document to a string format to use as a key (assumes documents can be serialized to JSON)\n",
        "            doc_str = dumps(doc)\n",
        "            # If the document is not yet in the fused_scores dictionary, add it with an initial score of 0\n",
        "            if doc_str not in fused_scores:\n",
        "                fused_scores[doc_str] = 0\n",
        "            # Retrieve the current score of the document, if any\n",
        "            previous_score = fused_scores[doc_str]\n",
        "            # Update the score of the document using the RRF formula: 1 / (rank + k)\n",
        "            fused_scores[doc_str] += 1 / (rank + k)\n",
        "\n",
        "    # Sort the documents based on their fused scores in descending order to get the final reranked results\n",
        "    reranked_results = [\n",
        "        (loads(doc), score)\n",
        "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    ]\n",
        "\n",
        "    # Return the reranked results as a list of tuples, each containing the document and its fused score\n",
        "    return reranked_results\n",
        "\n",
        "retrieval_chain_rag_fusion = generate_queries | retriever.map() | reciprocal_rank_fusion\n",
        "docs = retrieval_chain_rag_fusion.invoke({\"question\": question})\n",
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9OmSc_yROXUw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OmSc_yROXUw",
        "outputId": "808133c5-72a2-41b5-c3e3-e43d81b0f212"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'),\n",
              "  0.0661290322580645),\n",
              " (Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'),\n",
              "  0.06557377049180328),\n",
              " (Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Or\\n@article{weng2023agent,\\n  title   = \"LLM-powered Autonomous Agents\",\\n  author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Jun\",\\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#\\n[1] Wei et al. “Chain of thought prompting elicits reasoning in large language models.” NeurIPS 2022\\n[2] Yao et al. “Tree of Thoughts: Dliberate Problem Solving with Large Language Models.” arXiv preprint arXiv:2305.10601 (2023).\\n[3] Liu et al. “Chain of Hindsight Aligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al. “LLM+P: Empowering Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).'),\n",
              "  0.06505376344086021),\n",
              " (Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 13. The generative agent architecture. (Image source: Park et al. 2023)\\nThis fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, {{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...'),\n",
              "  0.031746031746031744),\n",
              " (Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='[17] Bran et al. “ChemCrow: Augmenting large-language models with chemistry tools.” arXiv preprint arXiv:2304.05376 (2023).\\n[18] Boiko et al. “Emergent autonomous scientific research capabilities of large language models.” arXiv preprint arXiv:2304.05332 (2023).\\n[19] Joon Sung Park, et al. “Generative Agents: Interactive Simulacra of Human Behavior.” arXiv preprint arXiv:2304.03442 (2023).\\n[20] AutoGPT. https://github.com/Significant-Gravitas/Auto-GPT\\n[21] GPT-Engineer. https://github.com/AntonOsika/gpt-engineer'),\n",
              "  0.015873015873015872),\n",
              " (Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.'),\n",
              "  0.015873015873015872)]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "eVODdwoZOciK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "eVODdwoZOciK",
        "outputId": "a9be9d3a-6559-4487-a515-7693a098191f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Task decomposition for LLM agents is the process of breaking down large, complex tasks into smaller, more manageable subgoals.  This can be achieved in several ways:  using simple prompts like \"Steps for XYZ. 1.\",  \"What are the subgoals for achieving XYZ?\"; using task-specific instructions (e.g., \"Write a story outline\" for writing a novel); or with human input.  Techniques like Chain of Thought (CoT) and Tree of Thoughts further enhance this process by guiding the LLM to think step-by-step or explore multiple reasoning possibilities at each step, respectively.'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# RAG\n",
        "template=\"\"\"Answer the following question based on this context:\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt=ChatPromptTemplate.from_template(template)\n",
        "\n",
        "final_rag_chain = (\n",
        "    {\"context\": retrieval_chain_rag_fusion,\n",
        "     \"question\": itemgetter(\"question\")}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "final_rag_chain.invoke({\"question\":question})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oTG3ilwJ6ipq",
      "metadata": {
        "id": "oTG3ilwJ6ipq"
      },
      "source": [
        "# Decomposition-\n",
        "We will break down user's query into set of sub-problems. LLM will generate multiple queries related to the question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "pStVu9pcQ3ho",
      "metadata": {
        "id": "pStVu9pcQ3ho"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# Decomposition\n",
        "template=\"\"\"\n",
        "    You are a helpful assistant that generates multiple sub-question related to an input question. \\n\n",
        "    The goal is to break down the input into a set of sub-problems / sub-questions that can be answers in isolation \\n\n",
        "    Generate multiple search queries related to:{question} \\n\n",
        "    Output (3 queries):\n",
        "\"\"\"\n",
        "prompt_decomposition=ChatPromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "Nb6kD_fH7x64",
      "metadata": {
        "id": "Nb6kD_fH7x64"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# LLM\n",
        "llm=ChatGoogleGenerativeAI(model='gemini-1.5-flash')\n",
        "\n",
        "# Chain\n",
        "generate_queries_decomposition=(prompt_decomposition | llm | StrOutputParser() | (lambda x:x.split('\\n')))\n",
        "\n",
        "# Run\n",
        "question=\"What are the main components of an LLM-powered autonomous agent system ?\"\n",
        "questions=generate_queries_decomposition.invoke({'question':question})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "TJgrXkOF8c6F",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJgrXkOF8c6F",
        "outputId": "60934860-b750-43aa-ef6a-cc217b1cda9d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Here are three search queries related to \"What are the main components of an LLM-powered autonomous agent system?\":',\n",
              " '',\n",
              " '1. **\"Architecture of LLM-based autonomous agents\"**: This query focuses on the overall structure and design principles.',\n",
              " '',\n",
              " '2. **\"Key modules in autonomous agents using large language models\"**: This query specifically targets the individual functional blocks within the system.',\n",
              " '',\n",
              " '3. **\"LLM agent components: memory, planning, action execution\"**: This query highlights three crucial aspects often found in such systems, prompting more specific results.']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "questions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Hnimqe_M9_ff",
      "metadata": {
        "id": "Hnimqe_M9_ff"
      },
      "source": [
        "# Answer Recursively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "lxS0K8ck8e5z",
      "metadata": {
        "id": "lxS0K8ck8e5z"
      },
      "outputs": [],
      "source": [
        "# Prompt\n",
        "template = \"\"\"Here is the question you need to answer:\n",
        "\n",
        "\\n --- \\n {question} \\n --- \\n\n",
        "\n",
        "Here is any available background question + answer pairs:\n",
        "\n",
        "\\n --- \\n {q_a_pairs} \\n --- \\n\n",
        "\n",
        "Here is additional context relevant to the question:\n",
        "\n",
        "\\n --- \\n {context} \\n --- \\n\n",
        "\n",
        "Use the above context and any background question + answer pairs to answer the question: \\n {question}\n",
        "\"\"\"\n",
        "\n",
        "decomposition_prompt = ChatPromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "2c_hjbsm-Hi3",
      "metadata": {
        "id": "2c_hjbsm-Hi3"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "def format_qa_pair(question, answer):\n",
        "    \"\"\"Format Q and A pair\"\"\"\n",
        "\n",
        "    formatted_string = \"\"\n",
        "    formatted_string += f\"Question: {question}\\nAnswer: {answer}\\n\\n\"\n",
        "    return formatted_string.strip()\n",
        "\n",
        "# llm\n",
        "llm=ChatGoogleGenerativeAI(model='gemini-1.5-flash',temperature=0)\n",
        "\n",
        "q_a_pairs = \"\"\n",
        "for q in questions:\n",
        "\n",
        "    rag_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | retriever,\n",
        "     \"question\": itemgetter(\"question\"),\n",
        "     \"q_a_pairs\": itemgetter(\"q_a_pairs\")}\n",
        "    | decomposition_prompt\n",
        "    | llm\n",
        "    | StrOutputParser())\n",
        "\n",
        "    answer = rag_chain.invoke({\"question\":q,\"q_a_pairs\":q_a_pairs})\n",
        "    q_a_pair = format_qa_pair(q,answer)\n",
        "    q_a_pairs = q_a_pairs + \"\\n---\\n\"+  q_a_pair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "mtNNSd1T_6Jt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "mtNNSd1T_6Jt",
        "outputId": "150ab106-34e9-4acc-8d42-43da4764b191"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Based on the provided text, an LLM agent comprises the following components related to memory, planning, and action execution:\\n\\n**1. Memory:**\\n\\n*   **Short-term memory:** This utilizes the LLM's in-context learning capabilities, essentially its immediate access to the current prompt and recent interactions.  It's limited (e.g., around 4000 words).\\n*   **Long-term memory:**  This is handled by an external vector store and fast retrieval system, allowing the agent to retain and recall information indefinitely.  Strategies for determining memory importance (recency, relevance, importance as judged by the LLM itself) are employed. A retrieval model surfaces relevant context. A reflection mechanism synthesizes memories into higher-level inferences to guide future behavior.\\n\\n**2. Planning:**\\n\\n*   **Subgoal decomposition:** The agent breaks down complex tasks into smaller, manageable subgoals.\\n*   **Reflection and refinement:** The agent self-critiques and reflects on past actions, learning from mistakes and improving future performance.  This includes analyzing past successes and failures to optimize future strategies.  Long-term planning can be challenging and may involve external tools like classical planners (as in LLM+P).  The planning process considers inter-agent communication and environmental information.\\n\\n**3. Action Execution:**\\n\\n*   **Tool use:** The agent interacts with external APIs and tools (e.g., internet access, code execution, proprietary data sources) to extend its capabilities beyond the LLM's inherent limitations.  This is crucial for achieving goals.\\n*   **Natural Language Interface:** This facilitates communication between the LLM and other components (memory, tools).  It handles input and output, translating between the LLM's internal representation and external formats.  However, its reliability is a significant challenge.  The action execution often involves prompting the LLM with information retrieved from memory and using the LLM's output to interact with the external world via tools.  The ReAct framework exemplifies this, integrating reasoning and acting within the LLM by combining task-specific actions and language-based reasoning.\\n\\n\\nIn summary, the LLM acts as the central decision-making unit, but its effectiveness relies heavily on these three interconnected components: a robust memory system for context and learning, a sophisticated planning module for handling complex tasks, and a mechanism for executing actions through tool use and a (potentially unreliable) natural language interface.\""
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "answer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RAlPA9xbASxC",
      "metadata": {
        "id": "RAlPA9xbASxC"
      },
      "source": [
        "# Anser Individually"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "-8JvvYxXAP_3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8JvvYxXAP_3",
        "outputId": "8565a17c-d2d5-482a-c664-2c9480e981a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-27-38821e4802e2>:23: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  retrieved_docs = retriever.get_relevant_documents(sub_question)\n"
          ]
        }
      ],
      "source": [
        "# Answer each sub-question individually\n",
        "\n",
        "from langchain import hub\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# RAG prompt\n",
        "prompt_rag = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "def retrieve_and_rag(question,prompt_rag,sub_question_generator_chain):\n",
        "    \"\"\"RAG on each sub-question\"\"\"\n",
        "\n",
        "    # Use our decomposition /\n",
        "    sub_questions = sub_question_generator_chain.invoke({\"question\":question})\n",
        "\n",
        "    # Initialize a list to hold RAG chain results\n",
        "    rag_results = []\n",
        "\n",
        "    for sub_question in sub_questions:\n",
        "\n",
        "        # Retrieve documents for each sub-question\n",
        "        retrieved_docs = retriever.get_relevant_documents(sub_question)\n",
        "\n",
        "        # Use retrieved documents and sub-question in RAG chain\n",
        "        answer = (prompt_rag | llm | StrOutputParser()).invoke({\"context\": retrieved_docs,\n",
        "                                                                \"question\": sub_question})\n",
        "        rag_results.append(answer)\n",
        "\n",
        "    return rag_results,sub_questions\n",
        "\n",
        "# Wrap the retrieval and RAG process in a RunnableLambda for integration into a chain\n",
        "answers, questions = retrieve_and_rag(question, prompt_rag, generate_queries_decomposition)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "C5lvHVVoF_IP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "C5lvHVVoF_IP",
        "outputId": "78f3a38f-7850-41a6-b86d-50cbfe827f25"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"LLM-powered autonomous agent systems typically consist of several key components working in concert.  The core is the **Large Language Model (LLM)** itself, acting as the central controller.  This LLM is complemented by:\\n\\n* **Planning:** This module allows the agent to break down complex tasks into smaller, more manageable subgoals.  This often involves subgoal decomposition and iterative refinement, sometimes incorporating reflection to improve future planning.\\n\\n* **Memory:**  This is crucial for maintaining context and learning from past experiences.  It usually includes both short-term memory (often limited, as seen in examples with 4000-word limits) and long-term memory for storing information over extended periods.\\n\\n* **Tools:**  These are external resources the agent can interact with to achieve its goals.  This could include internet access, specific APIs, or other software tools.\\n\\n* **Natural Language Interface:** This facilitates communication between the agent and the user or external systems.  However, the reliability of this interface is a known challenge.\\n\\nDifferent frameworks (like AutoGPT and BabyAGI) implement these components with varying designs and priorities, but the core functionalities remain consistent.  The agent's performance is often evaluated based on efficiency and its ability to continuously self-critique and improve its actions.\""
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def format_qa_pairs(questions, answers):\n",
        "    \"\"\"Format Q and A pairs\"\"\"\n",
        "\n",
        "    formatted_string = \"\"\n",
        "    for i, (question, answer) in enumerate(zip(questions, answers), start=1):\n",
        "        formatted_string += f\"Question {i}: {question}\\nAnswer {i}: {answer}\\n\\n\"\n",
        "    return formatted_string.strip()\n",
        "\n",
        "context = format_qa_pairs(questions, answers)\n",
        "\n",
        "# Prompt\n",
        "template = \"\"\"Here is a set of Q+A pairs:\n",
        "\n",
        "{context}\n",
        "\n",
        "Use these to synthesize an answer to the question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "final_rag_chain = (\n",
        "    prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "final_rag_chain.invoke({\"context\":context,\"question\":question})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ctdx5KwQZRNX",
      "metadata": {
        "id": "Ctdx5KwQZRNX"
      },
      "source": [
        "# Step Back"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "H9OsnoPHIAB1",
      "metadata": {
        "id": "H9OsnoPHIAB1"
      },
      "outputs": [],
      "source": [
        "# Few Shot Examples\n",
        "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
        "examples = [\n",
        "    {\n",
        "        \"input\": \"Could the members of The Police perform lawful arrests?\",\n",
        "        \"output\": \"what can the members of The Police do?\",\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Jan Sindel’s was born in what country?\",\n",
        "        \"output\": \"what is Jan Sindel’s personal history?\",\n",
        "    },\n",
        "]\n",
        "# We now transform these to example messages\n",
        "example_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"human\", \"{input}\"),\n",
        "        (\"ai\", \"{output}\"),\n",
        "    ]\n",
        ")\n",
        "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
        "    example_prompt=example_prompt,\n",
        "    examples=examples,\n",
        ")\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"\"\"You are an expert at world knowledge. Your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer. Here are a few examples:\"\"\",\n",
        "        ),\n",
        "        # Few shot examples\n",
        "        few_shot_prompt,\n",
        "        # New question\n",
        "        (\"user\", \"{question}\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "MRsKfFdvanrR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MRsKfFdvanrR",
        "outputId": "b437097f-7c70-4b49-c1bd-1a0f0bfd9b9a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'How do LLMs handle complex tasks?'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_queries_step_back = prompt | ChatGoogleGenerativeAI(model='gemini-1.5-flash',temperature=0) | StrOutputParser()\n",
        "question = \"What is task decomposition for LLM agents?\"\n",
        "generate_queries_step_back.invoke({\"question\": question})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "g6XfoRl7auWT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "g6XfoRl7auWT",
        "outputId": "23a650d0-2ff0-4a7f-eb37-ff87f0e6dcde"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Task decomposition, in the context of Large Language Model (LLM) agents, is the process of breaking down a complex task into smaller, more manageable sub-tasks.  This is crucial because LLMs, while powerful, have limitations in processing and reasoning about highly complex problems in a single step.  By decomposing the task, the agent can address each sub-task individually, making the overall problem tractable.\\n\\nSeveral methods exist for task decomposition:\\n\\n* **Chain of Thought (CoT):** This prompting technique instructs the LLM to \"think step by step,\" explicitly outlining the reasoning process.  This forces the model to decompose the task implicitly through its step-by-step reasoning.\\n\\n* **Tree of Thoughts (ToT):**  An extension of CoT, ToT explores multiple reasoning paths at each step, creating a tree structure of potential solutions.  This allows the agent to consider various approaches and potentially find better solutions than a linear, single-path approach.  Search strategies like Breadth-First Search (BFS) or Depth-First Search (DFS) can be used to explore this tree, with a classifier or majority vote used to evaluate the different paths.\\n\\n* **Direct Prompting:**  Simple prompts like \"Steps for XYZ. 1.\" or \"What are the subgoals for achieving XYZ?\" can directly elicit a decomposition from the LLM.\\n\\n* **Task-Specific Instructions:**  Providing task-specific instructions, such as \"Write a story outline\" for writing a novel, guides the LLM towards a natural decomposition relevant to the task.\\n\\n* **Human Input:**  In some cases, human intervention may be necessary to decompose a particularly complex or ambiguous task.\\n\\n\\nThe choice of decomposition method depends on the complexity of the task, the capabilities of the LLM, and the desired level of control over the decomposition process.  The goal is always to create a sequence of sub-tasks that the LLM can handle effectively, leading to the successful completion of the overall task.  However, challenges remain, particularly in long-term planning and handling unexpected errors during the execution of the decomposed sub-tasks.'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Response prompt\n",
        "response_prompt_template = \"\"\"You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant.\n",
        "\n",
        "# {normal_context}\n",
        "# {step_back_context}\n",
        "\n",
        "# Original Question: {question}\n",
        "# Answer:\"\"\"\n",
        "response_prompt = ChatPromptTemplate.from_template(response_prompt_template)\n",
        "\n",
        "chain = (\n",
        "    {\n",
        "        # Retrieve context using the normal question\n",
        "        \"normal_context\": RunnableLambda(lambda x: x[\"question\"]) | retriever,\n",
        "        # Retrieve context using the step-back question\n",
        "        \"step_back_context\": generate_queries_step_back | retriever,\n",
        "        # Pass on the question\n",
        "        \"question\": lambda x: x[\"question\"],\n",
        "    }\n",
        "    | response_prompt\n",
        "    | ChatGoogleGenerativeAI(model='gemini-1.5-flash',temperature=0)\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "chain.invoke({\"question\": question})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QQabXsx6a-Q6",
      "metadata": {
        "id": "QQabXsx6a-Q6"
      },
      "source": [
        "# HyDE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "uxtP4ZkLa4-r",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "uxtP4ZkLa4-r",
        "outputId": "fc8c92de-3dd7-4fe5-8b2a-a419bd3ff0a2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Task decomposition, in the context of Large Language Model (LLM) agents, refers to the process of breaking down a complex, high-level task into a sequence of simpler, more manageable sub-tasks that are individually tractable for the LLM.  This decomposition is crucial because LLMs, while capable of impressive feats of language understanding and generation, often struggle with tasks requiring extensive reasoning, memory, or external interaction.  A complex task like \"plan a surprise birthday party\" cannot be directly addressed by an LLM; instead, it must be decomposed into sub-tasks such as \"determine guest list,\" \"select a venue,\" \"create a budget,\" \"design invitations,\" and \"purchase supplies.\"  Each of these sub-tasks can then be further decomposed if necessary, creating a hierarchical task structure.  Effective task decomposition significantly improves the performance and reliability of LLM agents by mitigating the limitations of the underlying LLM and enabling the agent to leverage external tools and resources more effectively.  The choice of decomposition strategy, including the granularity of sub-tasks and their sequencing, significantly impacts the overall agent performance and is an active area of research.'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# HyDE document genration\n",
        "template = \"\"\"Please write a scientific paper passage to answer the question\n",
        "Question: {question}\n",
        "Passage:\"\"\"\n",
        "prompt_hyde = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "generate_docs_for_retrieval = (\n",
        "    prompt_hyde | ChatGoogleGenerativeAI(model='gemini-1.5-flash',temperature=0) | StrOutputParser()\n",
        ")\n",
        "\n",
        "# Run\n",
        "question = \"What is task decomposition for LLM agents?\"\n",
        "generate_docs_for_retrieval.invoke({\"question\":question})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "u35Y_1ahbHaO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u35Y_1ahbHaO",
        "outputId": "6993231f-235f-4a8f-867f-e65e2776cb9b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'),\n",
              " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'),\n",
              " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:'),\n",
              " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.')]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Retrieve\n",
        "retrieval_chain = generate_docs_for_retrieval | retriever\n",
        "retireved_docs = retrieval_chain.invoke({\"question\":question})\n",
        "retireved_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "t7_8wZRYbJ2l",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "t7_8wZRYbJ2l",
        "outputId": "0e00fe91-2d2d-42bb-8a15-f0aa98789fde"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Task decomposition, in the context of LLM-powered autonomous agents, is the process of breaking down large, complex tasks into smaller, more manageable sub-goals.  This allows the agent to handle complex problems more efficiently.  Methods for achieving this include:\\n\\n* **Chain of Thought (CoT):**  A prompting technique instructing the model to think step-by-step, decomposing the task into smaller steps.\\n* **Tree of Thoughts (ToT):** An extension of CoT that explores multiple reasoning possibilities at each step, creating a tree structure of potential solutions.\\n* **Simple prompting:**  Directly prompting the LLM with instructions like \"Steps for XYZ.\" or \"What are the subgoals for achieving XYZ?\".\\n* **Task-specific instructions:** Using instructions tailored to the task, such as \"Write a story outline.\" for writing a novel.\\n* **Human input:**  Directly providing the decomposition steps from a human.\\n* **External classical planner (LLM+P):** Using an external planner (like one using PDDL) to handle the decomposition, with the LLM translating the problem and solution into natural language.'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# RAG\n",
        "template = \"\"\"Answer the following question based on this context:\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "final_rag_chain = (\n",
        "    prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "final_rag_chain.invoke({\"context\":retireved_docs,\"question\":question})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3VaS3zBvbLuX",
      "metadata": {
        "id": "3VaS3zBvbLuX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
