tokenizer_config.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 17.0/17.0 [00:00<00:00, 32.6kB/s]
B:\Major_Git\LangChain-models\venv\Lib\site-packages\huggingface_hub\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\Users\ombha\.cache\huggingface\hub\models--lvwerra--gpt2-imdb. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.
To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development
  warnings.warn(message)
config.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 577/577 [00:00<00:00, 458kB/s]
vocab.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 899k/899k [00:00<00:00, 1.15MB/s]
merges.txt: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 456k/456k [00:00<00:00, 1.07MB/s]
special_tokens_map.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 90.0/90.0 [00:00<00:00, 181kB/s]
README.md: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7.81k/7.81k [00:00<00:00, 9.43MB/s]
B:\Major_Git\LangChain-models\venv\Lib\site-packages\huggingface_hub\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\Users\ombha\.cache\huggingface\hub\datasets--imdb. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.
To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development
  warnings.warn(message)
train-00000-of-00001.parquet: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 21.0M/21.0M [00:04<00:00, 4.59MB/s]
test-00000-of-00001.parquet: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 20.5M/20.5M [00:05<00:00, 3.68MB/s]
unsupervised-00000-of-00001.parquet: 100%|██████████████████████████████████████████████████████████████████████████████████| 42.0M/42.0M [00:10<00:00, 4.13MB/s]
Generating train split: 100%|███████████████████████████████████████████████████████████████████████████████████| 25000/25000 [00:00<00:00, 126953.16 examples/s]
Generating test split: 100%|████████████████████████████████████████████████████████████████████████████████████| 25000/25000 [00:00<00:00, 216887.23 examples/s]
Generating unsupervised split: 100%|████████████████████████████████████████████████████████████████████████████| 50000/50000 [00:00<00:00, 191726.29 examples/s]
Filter: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 25000/25000 [00:00<00:00, 80158.33 examples/s]
Map:   0%|                                                                                                                      | 0/24895 [00:00<?, ? examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors
Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 24895/24895 [00:40<00:00, 612.21 examples/s]
pytorch_model.bin: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 548M/548M [01:46<00:00, 5.17MB/s]
model.safetensors:   2%|█▉                                                                                                   | 10.5M/548M [00:01<01:33, 5.78MB/s]Traceback (most recent call last):
  File "B:\Major_Git\LangChain-models\RLHF\PPO\gpt_sentiment.py", line 67, in <module>
    ppo_trainer= PPOTrainer(config,
                ^^^^^^^^^^^^^^^^^^^
TypeError: PPOTrainer.__init__() got an unexpected keyword argument 'dataset'
model.safetensors: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 548M/548M [01:18<00:00, 7.02MB/s]
model.safetensors: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 548M/548M [01:29<00:00, 6.16MB/s]
