{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt_Length-and-Complexity_Management\n",
        "\n",
        "Effective prompt engineering often requires finding the right balance between providing enough context for the model to understand the task and keeping prompts concise for efficiency. Additionally, many real-world applications involve processing long documents or complex multi-step tasks, which can exceed the context window of LLMs. Learning to manage these challenges is crucial for building robust AI applications.\n",
        "\n",
        "## Key Components\n",
        "\n",
        "1. Balancing detail and conciseness in prompts\n",
        "2. Strategies for handling long contexts\n",
        "3. Practical examples using OpenAI's GPT model and LangChain"
      ],
      "metadata": {
        "id": "OwRifl7-5eiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install langchain langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "grZV-3am56E_",
        "outputId": "8fb9fc28-b66f-44af-98f6-67c12916433e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.56)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.39)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Downloading langchain_google_genai-2.1.4-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, google-ai-generativelanguage, langchain-google-genai\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.18 langchain-google-genai-2.1.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "e64ffbbde01c4eee9a31372321dbc48a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Y5c0DsZG5UZA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "os.environ['GOOGLE_API_KEY']=''\n",
        "\n",
        "# Inatiate the LLM\n",
        "llm=ChatGoogleGenerativeAI(model='gemini-1.5-flash')\n",
        "\n",
        "def get_completion(prompt):\n",
        "  \"\"\" Helper function to get model completion.\"\"\"\n",
        "  return llm.invoke(prompt).content"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Balencing Details and Conciseness"
      ],
      "metadata": {
        "id": "MmLayVRk6Roy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Detailed prompt\n",
        "detailed_prompt=PromptTemplate(\n",
        "    input_variables=['topic'],\n",
        "    template =\"\"\"\n",
        "          Please provide comprehensive explanation of {topic} include its defination.\n",
        "          historical context, key components, pratical applications and any relevant example.\n",
        "          Also discuss controversies and debates around topic and mention potential and future debelopement or trends\n",
        "    \"\"\"\n",
        "\n",
        ")\n",
        "\n",
        "# Concise prompt\n",
        "concise_prompt=PromptTemplate(\n",
        "    input_variables=['topic'],\n",
        "    template=\"\"\"\n",
        "        Briefly explain the {topic} and its main importance\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "topic='Artificial Intelligence'\n",
        "\n",
        "print('Detailed response:')\n",
        "print(llm.invoke(detailed_prompt.format(topic=topic)).content)\n",
        "\n",
        "print('\\n Concise response:')\n",
        "print(llm.invoke(concise_prompt.format(topic=topic)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szScPk9-59uk",
        "outputId": "92965784-6b76-478d-9912-baf621e808db"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detailed response:\n",
            "## Artificial Intelligence: A Comprehensive Overview\n",
            "\n",
            "**Definition:**\n",
            "\n",
            "Artificial intelligence (AI) is a broad field encompassing the theory and development of computer systems able to perform tasks that normally require human intelligence.  These tasks include learning, reasoning, problem-solving, perception, and natural language understanding.  It's important to distinguish between narrow or weak AI (designed for specific tasks) and general or strong AI (hypothetical AI with human-level intelligence and adaptability across diverse domains).  Currently, most AI systems fall under the category of narrow AI.\n",
            "\n",
            "**Historical Context:**\n",
            "\n",
            "The conceptual roots of AI can be traced back to ancient myths of artificial beings endowed with intelligence.  However, the formal field emerged in the mid-20th century:\n",
            "\n",
            "* **1950s:** Alan Turing's seminal work on computing and his \"Turing Test\" laid the groundwork for evaluating machine intelligence. The Dartmouth Workshop (1956) is widely considered the birthplace of AI as a distinct field of study. Early efforts focused on symbolic reasoning and logic-based approaches.\n",
            "* **1960s-1970s:** Initial optimism gave way to the first \"AI winter\" as limitations of early techniques became apparent.  Progress was slow due to computational constraints and the complexity of real-world problems.\n",
            "* **1980s:** Expert systems, employing rule-based reasoning, experienced a resurgence of interest.  However, the limitations of these systems (brittleness, difficulty in knowledge acquisition) led to another AI winter.\n",
            "* **1990s-Present:** Advances in computing power, the availability of large datasets, and the development of new algorithms (e.g., machine learning, deep learning) sparked a renaissance in AI.  The rise of the internet and the proliferation of data fueled this progress.  We are currently experiencing a period of rapid advancement and widespread application of AI.\n",
            "\n",
            "\n",
            "**Key Components:**\n",
            "\n",
            "Several key components underpin the development and application of AI:\n",
            "\n",
            "* **Machine Learning (ML):** Algorithms that allow systems to learn from data without explicit programming.  This includes supervised learning (learning from labeled data), unsupervised learning (finding patterns in unlabeled data), and reinforcement learning (learning through trial and error).\n",
            "* **Deep Learning (DL):** A subset of ML employing artificial neural networks with multiple layers to extract higher-level features from data.  DL has been crucial for breakthroughs in image recognition, natural language processing, and other areas.\n",
            "* **Natural Language Processing (NLP):** Enables computers to understand, interpret, and generate human language.  Applications include machine translation, chatbots, and sentiment analysis.\n",
            "* **Computer Vision:** Allows computers to \"see\" and interpret images and videos.  Applications include object recognition, image classification, and facial recognition.\n",
            "* **Robotics:** Integrates AI with physical robots to enable autonomous actions and interaction with the physical world.\n",
            "* **Knowledge Representation and Reasoning:**  Methods for representing and manipulating knowledge to enable logical inference and problem-solving.\n",
            "\n",
            "\n",
            "**Practical Applications:**\n",
            "\n",
            "AI is transforming numerous industries:\n",
            "\n",
            "* **Healthcare:** Diagnosis assistance, drug discovery, personalized medicine, robotic surgery.\n",
            "* **Finance:** Fraud detection, algorithmic trading, risk management, customer service chatbots.\n",
            "* **Transportation:** Self-driving cars, traffic optimization, autonomous delivery systems.\n",
            "* **Retail:** Personalized recommendations, inventory management, customer service chatbots.\n",
            "* **Manufacturing:** Predictive maintenance, quality control, process optimization.\n",
            "* **Education:** Personalized learning platforms, automated grading systems, intelligent tutoring systems.\n",
            "\n",
            "\n",
            "**Example:**  Google's AlphaGo, a program that defeated a world champion Go player, exemplifies the power of deep reinforcement learning.  Other examples include Siri (NLP), self-driving cars (computer vision and robotics), and Netflix's recommendation system (ML).\n",
            "\n",
            "\n",
            "**Controversies and Debates:**\n",
            "\n",
            "The rapid advancement of AI raises several ethical and societal concerns:\n",
            "\n",
            "* **Job displacement:** Automation driven by AI could lead to significant job losses in various sectors.\n",
            "* **Bias and fairness:** AI systems trained on biased data can perpetuate and amplify existing societal biases.\n",
            "* **Privacy and surveillance:** The use of AI in surveillance technologies raises concerns about privacy violations.\n",
            "* **Autonomous weapons systems:** The development of lethal autonomous weapons raises ethical and security concerns.\n",
            "* **Explainability and transparency:**  The \"black box\" nature of some AI algorithms makes it difficult to understand their decision-making processes, raising concerns about accountability.\n",
            "* **Existential risk:**  Some experts warn about the potential long-term risks of highly advanced AI, though this remains a subject of debate.\n",
            "\n",
            "\n",
            "**Potential and Future Developments:**\n",
            "\n",
            "Future trends in AI include:\n",
            "\n",
            "* **Explainable AI (XAI):**  Developing more transparent and interpretable AI systems.\n",
            "* **Edge AI:**  Deploying AI algorithms on devices at the edge of the network (e.g., smartphones, IoT devices) to reduce latency and improve privacy.\n",
            "* **Federated learning:**  Training AI models on decentralized data sources without sharing the data itself.\n",
            "* **AI for Science:**  Using AI to accelerate scientific discovery in fields like medicine, materials science, and climate change.\n",
            "* **Human-AI collaboration:**  Designing AI systems that work effectively alongside humans, augmenting human capabilities rather than replacing them.\n",
            "\n",
            "\n",
            "In conclusion, AI is a rapidly evolving field with immense potential to benefit society.  However, it's crucial to address the ethical and societal challenges associated with its development and deployment to ensure that AI is used responsibly and benefits all of humanity.\n",
            "\n",
            " Concise response:\n",
            "content='Artificial intelligence (AI) is the simulation of human intelligence processes by machines, especially computer systems.  These processes include learning (acquiring information and rules for using the information), reasoning (using rules to reach approximate or definite conclusions), and self-correction.\\n\\nIts main importance lies in its ability to automate tasks, analyze vast amounts of data to identify patterns and insights humans might miss, and solve complex problems more efficiently than humans alone. This leads to advancements in various fields, including healthcare, finance, transportation, and manufacturing, ultimately improving productivity, efficiency, and decision-making.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []} id='run-5838738c-2a5d-4373-a997-26a9ae5c98a6-0' usage_metadata={'input_tokens': 14, 'output_tokens': 117, 'total_tokens': 131, 'input_token_details': {'cache_read': 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis Prompt Balance"
      ],
      "metadata": {
        "id": "pS0S9l6_755H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "analysis_prompt = PromptTemplate(\n",
        "    input_variables=[\"detailed_response\", \"concise_response\"],\n",
        "    template=\"\"\"Compare the following two responses on artificial intelligence:\n",
        "\n",
        "Detailed response:\n",
        "{detailed_response}\n",
        "\n",
        "Concise response:\n",
        "{concise_response}\n",
        "\n",
        "Analyze the differences in terms of:\n",
        "1. Information coverage\n",
        "2. Clarity and focus\n",
        "3. Potential use cases for each type of response\n",
        "\n",
        "Then, suggest strategies for balancing detail and conciseness in prompts.\"\"\"\n",
        ")\n",
        "\n",
        "detailed_response = llm.invoke(detailed_prompt.format(topic=topic)).content\n",
        "concise_response = llm.invoke(concise_prompt.format(topic=topic)).content\n",
        "\n",
        "analysis = llm.invoke(analysis_prompt.format(\n",
        "    detailed_response=detailed_response,\n",
        "    concise_response=concise_response\n",
        ")).content\n",
        "\n",
        "print(analysis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ei0BTHfj7x0t",
        "outputId": "680fbb37-2d50-478d-b0fb-ec95edb1c76d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's analyze the differences between the two responses:\n",
            "\n",
            "**1. Information Coverage:**\n",
            "\n",
            "* **Detailed Response:** Offers a comprehensive overview, covering the definition, historical context, key components (ML, DL, NLP, Computer Vision, Robotics, Knowledge Representation), practical applications across multiple industries, controversies and debates (job displacement, bias, privacy, autonomous weapons, explainability), and potential future developments (AGI, XAI, AI safety, human-AI collaboration, edge AI, quantum AI).  It's encyclopedic in its scope.\n",
            "\n",
            "* **Concise Response:** Provides a basic definition and focuses primarily on the importance and broad applications of AI.  It lacks historical context, detailed explanation of AI components, ethical considerations, and future trends.  It's a high-level summary.\n",
            "\n",
            "\n",
            "**2. Clarity and Focus:**\n",
            "\n",
            "* **Detailed Response:** While comprehensive, the clarity could be improved with better structuring and use of headings/subheadings.  The sheer amount of information can feel overwhelming. The focus is broad, aiming to cover all major aspects of AI.\n",
            "\n",
            "* **Concise Response:**  Crystal clear and easy to understand.  The focus is laser-sharp on the core value proposition of AI: automation, data analysis, and improved decision-making.  It sacrifices depth for simplicity.\n",
            "\n",
            "\n",
            "**3. Potential Use Cases for Each Type of Response:**\n",
            "\n",
            "* **Detailed Response:** Ideal for educational purposes (lectures, textbooks, research papers), in-depth reports, or situations where a complete understanding of AI is needed.  Suitable for audiences with some prior knowledge or a strong desire to learn deeply.\n",
            "\n",
            "* **Concise Response:** Best for quick summaries, introductory materials, elevator pitches, or when communicating with a non-technical audience.  Useful for getting a general grasp of AI without getting bogged down in details.\n",
            "\n",
            "\n",
            "**Strategies for Balancing Detail and Conciseness in Prompts:**\n",
            "\n",
            "To elicit responses that are both informative and concise, consider these strategies when crafting prompts:\n",
            "\n",
            "* **Specify the desired length or format:**  Use phrases like \"provide a concise summary (200 words),\" \"give a detailed explanation (500-750 words),\" or \"create an outline.\"\n",
            "\n",
            "* **Clearly define the target audience:**  Mention whether the response should be tailored for experts, novices, or a general audience.  This helps determine the appropriate level of detail.\n",
            "\n",
            "* **Focus the prompt with specific questions:** Instead of asking a broad question like \"Explain AI,\" ask targeted questions such as \"What are the three most significant ethical concerns surrounding AI?\" or \"Describe the role of machine learning in self-driving cars.\"\n",
            "\n",
            "* **Use keywords to guide the level of detail:**  Words like \"overview,\" \"summary,\" \"introduction,\" \"analysis,\" or \"in-depth\" signal the desired level of detail.\n",
            "\n",
            "* **Provide examples:** Show what kind of response you're looking for by providing examples of desired detail level and structure.\n",
            "\n",
            "* **Iterative prompting:** Ask a broad question initially, then follow up with more specific questions to refine the response and achieve the desired balance between detail and conciseness.  This allows for clarification and focused information gathering.\n",
            "\n",
            "\n",
            "By employing these strategies, you can effectively guide the AI to produce responses that are both informative and appropriately concise for the given context.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Strategies for Handeling Long Contexts\n",
        "\n",
        "1. Chunking- It involves breaking long texts into smaller"
      ],
      "metadata": {
        "id": "1i29GG558Lz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# [A long passage about artificial intelligence, its history, applications, and future prospects...]\n",
        "\n",
        "long_text = \"\"\"\n",
        "Artificial intelligence (AI) is a branch of computer science that aims to create intelligent machines that can simulate human cognitive processes.\n",
        "The field of AI has a rich history dating back to the 1950s, with key milestones such as the development of the first neural networks and expert systems.\n",
        "AI encompasses a wide range of subfields, including machine learning, natural language processing, computer vision, and robotics.\n",
        "Practical applications of AI include speech recognition, image classification, autonomous vehicles, and medical diagnosis.\n",
        "AI has the potential to revolutionize many industries, from healthcare and finance to transportation and entertainment.\n",
        "However, there are ongoing debates and controversies surrounding AI, such as concerns about job displacement, bias in algorithms, and the ethical implications of autonomous systems.\n",
        "Looking ahead, the future of AI holds promise for advancements in areas like explainable AI, AI ethics, and human-AI collaboration.\n",
        "The intersection of AI with other technologies like blockchain, quantum computing, and biotechnology will likely shape the future of the field.\n",
        "But as AI continues to evolve, it is essential to consider the societal impact and ethical implications of these technologies.\n",
        "One of the key challenges for AI researchers and developers is to strike a balance between innovation and responsibility, ensuring that AI benefits society as\n",
        "a whole while minimizing potential risks.\n",
        "If managed effectively, AI has the potential to transform our world in ways we can only begin to imagine.\n",
        "Though the future of AI is uncertain, one thing is clear: the impact of artificial intelligence will be profound and far-reaching.\n",
        "\"\"\"\n",
        "\n",
        "# Initialize the text splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        "    length_function=len\n",
        ")\n",
        "\n",
        "# Split the text into chunks\n",
        "chunks = text_splitter.split_text(long_text)\n",
        "\n",
        "print(f\"Number of chunks: {len(chunks)}\")\n",
        "print(f\"First chunk: {chunks[0][:200]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1jY_2tw8Fcz",
        "outputId": "2835b83c-f1f0-4ebe-d8a2-f020c276d141"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of chunks: 2\n",
            "First chunk: Artificial intelligence (AI) is a branch of computer science that aims to create intelligent machines that can simulate human cognitive processes.\n",
            "The field of AI has a rich history dating back to the...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Summarization- Summarization used to condense long texts to retrieve key information"
      ],
      "metadata": {
        "id": "xHTUDVoA8okY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.docstore.document import Document\n",
        "from langchain.chains import load_summarize_chain\n",
        "\n",
        "# Convert text chunks to Document objects\n",
        "doc_chunks = [Document(page_content=chunk) for chunk in chunks]\n",
        "\n",
        "# Load the summarization chain\n",
        "chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
        "\n",
        "# Summarize the long text\n",
        "summary_result = chain.invoke(doc_chunks)\n",
        "\n",
        "print(\"Summary:\")\n",
        "print(summary_result['output_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAJ8VE6B8iv6",
        "outputId": "f9b47911-27ab-42d2-ec5d-363c6958529d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            "AI's rapid advancement since the 1950s has revolutionized industries but raises ethical concerns about job displacement and bias.  The future of AI hinges on responsible innovation, focusing on explainability, ethics, and human-AI collaboration to maximize benefits while mitigating risks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Iterative Processing-\n",
        "For complex tak we use iterative processing."
      ],
      "metadata": {
        "id": "p7MTjIUj-Gb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def iterative_analysis(text, steps):\n",
        "    \"\"\"\n",
        "    Perform iterative analysis on a given text.\n",
        "\n",
        "    Args:\n",
        "    text (str): The text to analyze.\n",
        "    steps (list): List of analysis steps to perform.\n",
        "\n",
        "    Returns:\n",
        "    str: The final analysis result.\n",
        "    \"\"\"\n",
        "    result = text\n",
        "    for step in steps:\n",
        "        prompt = PromptTemplate(\n",
        "            input_variables=[\"text\"],\n",
        "            template=f\"Analyze the following text. {step}\\n\\nText: {{text}}\\n\\nAnalysis:\"\n",
        "        )\n",
        "        result = llm.invoke(prompt.format(text=result)).content\n",
        "    return result\n",
        "\n",
        "analysis_steps = [\n",
        "    \"Identify the main topics discussed.\",\n",
        "    \"Summarize the key points for each topic.\",\n",
        "    \"Provide a brief conclusion based on the analysis.\"\n",
        "]\n",
        "\n",
        "final_analysis = iterative_analysis(long_text, analysis_steps)\n",
        "print(\"Final Analysis:\")\n",
        "print(final_analysis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qwNGoPO9qwe",
        "outputId": "5e332542-ff74-4685-eaa4-565b85beb305"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Analysis:\n",
            "The analysis shows the text provides a balanced and comprehensive overview of Artificial Intelligence.  It successfully integrates ethical considerations throughout its discussion of AI's history, current applications, future potential, and societal impact, highlighting the crucial need for responsible development and deployment.  The conclusion accurately reflects this balanced perspective.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tips_prompt = \"\"\"\n",
        "Based on the examples and strategies we've explored for managing prompt length and complexity,\n",
        "provide a list of 5 practical tips for developers working with large language models.\n",
        "Each tip should be concise and actionable.\n",
        "\"\"\"\n",
        "\n",
        "tips = llm.invoke(tips_prompt).content\n",
        "print(tips)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ig_aCn9Q-VEr",
        "outputId": "2e2ab407-a2d0-4f45-97d7-4063c223e415"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. **Chunking:** Break down complex tasks into smaller, manageable prompts.\n",
            "\n",
            "2. **Prioritization:** Focus prompts on the most crucial information; omit unnecessary details.\n",
            "\n",
            "3. **Iteration:** Refine prompts based on initial model responses; iterate for improved results.\n",
            "\n",
            "4. **Structured Input:** Use consistent formatting (e.g., JSON) for structured data input.\n",
            "\n",
            "5. **Contextual Awareness:** Provide sufficient but concise context within the prompt to guide the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8p0xeqKn-YCq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}